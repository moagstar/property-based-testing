{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "$('#run_all_cells_below').click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Property Based Testing\n",
    "## (Using Hypothesis)<br><br><br>\n",
    "### Amsterdam Python Meetup\n",
    "### 26 April 2017<br><br><br>\n",
    "### Daniel Bradburn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Property based testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Choosing properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Generating data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Model based testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Django"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "say we have a run length encoding function. We encode a string as characters and the number of consecutive occurrences of that character. let's just test this out with something simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def encode(input_string):\n",
    "    count = 1\n",
    "    prev = ''\n",
    "    lst = []\n",
    "    for character in input_string:\n",
    "        if character != prev:\n",
    "            if prev:\n",
    "                lst.append((prev, count))\n",
    "            count = 1\n",
    "            prev = character\n",
    "        else:\n",
    "            count += 1\n",
    "    else:\n",
    "        lst.append((character, count))\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('h', 1), ('e', 1), ('l', 8), ('o', 1)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode('hellllllllo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "and we also have a decode function which reconstructs the string let's just check this function, let's use the output from the encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def decode(lst):\n",
    "    return ''.join(c * n for c, n in lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hellllllo'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode([('h', 1), ('e', 1), ('l', 6), ('o', 1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "but it's probably best to formalize this in a unit test. I'm using pytest here, but you could use unittest or your favourite test runner, the principal is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def test_run_length_encode():\n",
    "    input_data = \"hello\"\n",
    "    expected = [('h', 1), ('e', 1), ('l', 2), ('o', 1)]\n",
    "    actual = encode(input_data)\n",
    "    assert actual == expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\r\n",
      "\r\n",
      "======================== 21 tests deselected =========================\r\n",
      "\r\n",
      "1 passed, 21 deselected in 0.07 seconds\r\n"
     ]
    }
   ],
   "source": [
    "!sh pytest_run.sh test_run_length_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def test_run_length_decode():\n",
    "    input_data = [('h', 1), ('e', 1), ('l', 2), ('o', 1)]\n",
    "    expected = \"hello\"\n",
    "    actual = decode(input_data)\n",
    "    assert actual == expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\r\n",
      "\r\n",
      "======================== 21 tests deselected =========================\r\n",
      "\r\n",
      "1 passed, 21 deselected in 0.07 seconds\r\n"
     ]
    }
   ],
   "source": [
    "!sh pytest_run.sh test_run_length_decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import pytest\n",
    "\n",
    "examples = ['hello', 'python', 'uhm...']\n",
    "\n",
    "@pytest.mark.parametrize('input_data', examples)\n",
    "def test_parameterized_run_length_encode_decode(input_data):\n",
    "    assert decode(encode(input_data)) == input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\r\n",
      "\r\n",
      "======================== 19 tests deselected =========================\r\n",
      "\r\n",
      "3 passed, 19 deselected in 0.08 seconds\r\n"
     ]
    }
   ],
   "source": [
    "!sh pytest_run.sh test_parameterized_run_length_encode_decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import random, string\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "random_letter = lambda: random.choice(string.ascii_letters)\n",
    "random_range = lambda m: range(random.randint(0, m))\n",
    "random_word = lambda m: (random_letter() for i in random_range(m))\n",
    "random_words = lambda n, m: (''.join(random_word(m)) for n in range(n))\n",
    "\n",
    "@pytest.mark.parametrize('input_data', random_words(5, 10))\n",
    "def test_fuzzed_run_length_encode_decode(input_data):\n",
    "    assert decode(encode(input_data)) == input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".....\r\n",
      "\r\n",
      "======================== 17 tests deselected =========================\r\n",
      "\r\n",
      "5 passed, 17 deselected in 0.08 seconds\r\n"
     ]
    }
   ],
   "source": [
    "!sh pytest_run.sh test_fuzzed_run_length_encode_decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from hypothesis import strategies as st\n",
    "from hypothesis import given\n",
    "\n",
    "@given(st.text())\n",
    "def test_property_based_run_length_encode_decode(input_data):\n",
    "    assert decode(encode(input_data)) == input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F.\r\n",
      "\r\n",
      "============================== FAILURES ==============================\r\n",
      "\r\n",
      "\r\n",
      "____________ test_property_based_run_length_encode_decode ____________\r\n",
      "\r\n",
      "\r\n",
      "test_1_introduction.py:231: in test_property_based_run_length_encode_decode\r\n",
      "    def test_property_based_run_length_encode_decode(input_data):\r\n",
      "\r\n",
      ".venv/hypothesis/core.py:524: in wrapped_test\r\n",
      "    print_example=True, is_final=True\r\n",
      "\r\n",
      ".venv/hypothesis/executors.py:58: in default_new_style_executor\r\n",
      "    return function(data)\r\n",
      "\r\n",
      ".venv/hypothesis/core.py:111: in run\r\n",
      "    return test(*args, **kwargs)\r\n",
      "\r\n",
      "test_1_introduction.py:232: in test_property_based_run_length_encode_decode\r\n",
      "    assert decode(encode(input_data)) == input_data\r\n",
      "\r\n",
      "test_1_introduction.py:83: in encode\r\n",
      "    lst.append((character, count))\r\n",
      "E   UnboundLocalError: local variable 'character' referenced before assignment\r\n",
      "\r\n",
      "----------------------------- Hypothesis -----------------------------\r\n",
      "\r\n",
      "Falsifying example: test_property_based_run_length_encode_decode(input_data='')\r\n",
      "\r\n",
      "======================== 20 tests deselected =========================\r\n",
      "\r\n",
      "1 failed, 1 passed, 20 deselected in 0.21 seconds\r\n"
     ]
    }
   ],
   "source": [
    "!sh pytest_run.sh test_property_based_run_length_encode_decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def encode_fixed(input_string):\n",
    "    count = 1\n",
    "    prev = ''\n",
    "    lst = []\n",
    "    character = ''\n",
    "    for character in input_string:\n",
    "        if character != prev:\n",
    "            if prev:\n",
    "                lst.append((prev, count))\n",
    "            count = 1\n",
    "            prev = character\n",
    "        else:\n",
    "            count += 1\n",
    "    else:\n",
    "        lst.append((character, count))\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "@given(st.text())\n",
    "def test_property_based_run_length_encode_decode_fixed(input_data):\n",
    "    assert decode(encode_fixed(input_data)) == input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\r\n",
      "\r\n",
      "======================== 21 tests deselected =========================\r\n",
      "\r\n",
      "1 passed, 21 deselected in 0.15 seconds\r\n"
     ]
    }
   ],
   "source": [
    "!sh pytest_run.sh test_property_based_run_length_encode_decode_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class Queue(object):\n",
    "\n",
    "    def __init__(self, max_size):\n",
    "        self._buffer = [None] * max_size\n",
    "        self._in, self._out, self.max_size = 0, 0, max_size\n",
    "\n",
    "    def put(self, item):\n",
    "        self._buffer[self._in] = item\n",
    "        self._in = (self._in + 1) % self.max_size\n",
    "\n",
    "    def get(self):\n",
    "        result = self._buffer[self._out]\n",
    "        self._out = (self._out + 1) % self.max_size\n",
    "        return result\n",
    "\n",
    "    def __len__(self):\n",
    "        return (self._in - self._out) % self.max_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from hypothesis import strategies as st\n",
    "from hypothesis.stateful import RuleBasedStateMachine, rule, precondition\n",
    "\n",
    "class QueueMachine(RuleBasedStateMachine):\n",
    "\n",
    "    Actual, Model = Queue, list\n",
    "\n",
    "    def is_created(self): return hasattr(self, 'actual')\n",
    "    def is_not_empty(self): return self.is_created() and len(self.model)\n",
    "\n",
    "    @precondition(lambda self: not self.is_created())\n",
    "    @rule(max_size=st.integers(min_value=1, max_value=10))\n",
    "    def new(self, max_size):\n",
    "        self.actual, self.model = self.Actual(max_size), self.Model()\n",
    "        self.max_size = max_size\n",
    "\n",
    "    @precondition(is_created)\n",
    "    @rule(item=st.integers())\n",
    "    def put(self, item):\n",
    "        self.actual.put(item)\n",
    "        self.model.append(item)\n",
    "\n",
    "    @precondition(is_not_empty)\n",
    "    @rule()\n",
    "    def get(self):\n",
    "        actual, model = self.actual.get(), self.model.pop()\n",
    "        assert actual == model\n",
    "\n",
    "    @precondition(is_created)\n",
    "    @rule()\n",
    "    def size(self):\n",
    "        actual, model = len(self.actual), len(self.model)\n",
    "        assert actual == model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F\r\n",
      "\r\n",
      "============================== FAILURES ==============================\r\n",
      "\r\n",
      "\r\n",
      "_____________________ test_model_based_1.runTest _____________________\r\n",
      "\r\n",
      "\r\n",
      ".venv/hypothesis/stateful.py:182: in runTest\r\n",
      "    run_state_machine_as_test(state_machine_class)\r\n",
      "\r\n",
      ".venv/hypothesis/stateful.py:109: in run_state_machine_as_test\r\n",
      "    breaker.run(state_machine_factory(), print_steps=True)\r\n",
      "\r\n",
      ".venv/hypothesis/stateful.py:237: in run\r\n",
      "    state_machine.execute_step(value)\r\n",
      "\r\n",
      ".venv/hypothesis/stateful.py:512: in execute_step\r\n",
      "    result = rule.function(self, **data)\r\n",
      "\r\n",
      "test_4_model_based_testing.py:72: in get\r\n",
      "    assert actual == model\r\n",
      "E   AssertionError: assert 0 == 1\r\n",
      "\r\n",
      "----------------------------- Hypothesis -----------------------------\r\n",
      "\r\n",
      "Step #1: new(max_size=2)\r\n",
      "Step #2: put(item=0)\r\n",
      "Step #3: put(item=1)\r\n",
      "Step #4: get()\r\n",
      "\r\n",
      "======================== 21 tests deselected =========================\r\n",
      "\r\n",
      "1 failed, 21 deselected in 0.16 seconds\r\n"
     ]
    }
   ],
   "source": [
    "test_model_based_1 = QueueMachine.TestCase\n",
    "!sh pytest_run.sh test_model_based_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class QueueMachine2(QueueMachine):\n",
    "            \n",
    "    @precondition(QueueMachine.is_created)\n",
    "    @rule(item=st.integers())\n",
    "    def put(self, item):\n",
    "        self.actual.put(item)\n",
    "        self.model.insert(0, item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F\r\n",
      "\r\n",
      "============================== FAILURES ==============================\r\n",
      "\r\n",
      "\r\n",
      "_____________________ test_model_based_2.runTest _____________________\r\n",
      "\r\n",
      "\r\n",
      ".venv/hypothesis/stateful.py:182: in runTest\r\n",
      "    run_state_machine_as_test(state_machine_class)\r\n",
      "\r\n",
      ".venv/hypothesis/stateful.py:109: in run_state_machine_as_test\r\n",
      "    breaker.run(state_machine_factory(), print_steps=True)\r\n",
      "\r\n",
      ".venv/hypothesis/stateful.py:237: in run\r\n",
      "    state_machine.execute_step(value)\r\n",
      "\r\n",
      ".venv/hypothesis/stateful.py:512: in execute_step\r\n",
      "    result = rule.function(self, **data)\r\n",
      "\r\n",
      "test_4_model_based_testing.py:78: in size\r\n",
      "    assert actual == model\r\n",
      "E   AssertionError: assert 0 == 2\r\n",
      "\r\n",
      "----------------------------- Hypothesis -----------------------------\r\n",
      "\r\n",
      "Step #1: new(max_size=1)\r\n",
      "Step #2: put(item=0)\r\n",
      "Step #3: put(item=0)\r\n",
      "Step #4: size()\r\n",
      "\r\n",
      "======================== 21 tests deselected =========================\r\n",
      "\r\n",
      "1 failed, 21 deselected in 0.17 seconds\r\n"
     ]
    }
   ],
   "source": [
    "test_model_based_2 = QueueMachine2.TestCase\n",
    "!sh pytest_run.sh test_model_based_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class QueueMachine3(QueueMachine2):\n",
    "\n",
    "    def is_not_full(self):\n",
    "        return self.is_created() and len(self.model) < self.max_size\n",
    "\n",
    "    @precondition(is_not_full)\n",
    "    @rule(item=st.integers())\n",
    "    def put(self, item):\n",
    "        QueueMachine2.put(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F\r\n",
      "\r\n",
      "============================== FAILURES ==============================\r\n",
      "\r\n",
      "\r\n",
      "_____________________ test_model_based_3.runTest _____________________\r\n",
      "\r\n",
      "\r\n",
      ".venv/hypothesis/stateful.py:182: in runTest\r\n",
      "    run_state_machine_as_test(state_machine_class)\r\n",
      "\r\n",
      ".venv/hypothesis/stateful.py:109: in run_state_machine_as_test\r\n",
      "    breaker.run(state_machine_factory(), print_steps=True)\r\n",
      "\r\n",
      ".venv/hypothesis/stateful.py:237: in run\r\n",
      "    state_machine.execute_step(value)\r\n",
      "\r\n",
      ".venv/hypothesis/stateful.py:512: in execute_step\r\n",
      "    result = rule.function(self, **data)\r\n",
      "\r\n",
      "test_4_model_based_testing.py:78: in size\r\n",
      "    assert actual == model\r\n",
      "E   AssertionError: assert 0 == 1\r\n",
      "\r\n",
      "----------------------------- Hypothesis -----------------------------\r\n",
      "\r\n",
      "Step #1: new(max_size=1)\r\n",
      "Step #2: put(item=0)\r\n",
      "Step #3: size()\r\n",
      "\r\n",
      "======================== 21 tests deselected =========================\r\n",
      "\r\n",
      "1 failed, 21 deselected in 0.15 seconds\r\n"
     ]
    }
   ],
   "source": [
    "test_model_based_3 = QueueMachine3.TestCase\n",
    "!sh pytest_run.sh test_model_based_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class Queue2(Queue):\n",
    "    def __init__(self, max_size):\n",
    "        super(Queue2, self).__init__(max_size + 1)\n",
    "\n",
    "class QueueMachine4(QueueMachine3):\n",
    "    Actual = Queue2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "test_model_based_4 = QueueMachine4.TestCase\n",
    "!sh pytest_run.sh test_model_based_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$('#clear_all_output').click()"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "$('#clear_all_output').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<link href=\"https://fonts.googleapis.com/css?family=Poppins\" rel=\"stylesheet\">\n",
       "<style>body { font-family: 'Poppins', serif !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<link href=\"https://fonts.googleapis.com/css?family=Poppins\" rel=\"stylesheet\">\n",
    "<style>body { font-family: 'Poppins', serif !important; }</style>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "livereveal": {
   "scroll": true,
   "theme": "black",
   "transition": "fade"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
