{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "$('#run_all_cells_below').click()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Property Based Testing\n",
    "## (Using Hypothesis)<br><br><br>\n",
    "### Amsterdam Python Meetup\n",
    "### 27 April 2017<br><br><br>\n",
    "### Daniel Bradburn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Property based testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Choosing properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Generating data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Model based testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Django"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "say we have a run length encoding function. We encode a string as characters and the number of consecutive occurrences of that character. let's just test this out with something simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def encode(input_string):\n",
    "    count = 1\n",
    "    prev = ''\n",
    "    lst = []\n",
    "    for character in input_string:\n",
    "        if character != prev:\n",
    "            if prev:\n",
    "                lst.append((prev, count))\n",
    "            count = 1\n",
    "            prev = character\n",
    "        else:\n",
    "            count += 1\n",
    "    else:\n",
    "        lst.append((character, count))\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "encode('hello')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "and we also have a decode function which reconstructs the string let's just check this function, let's use the output from the encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def decode(lst):\n",
    "    return ''.join(c * n for c, n in lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "decode([('h', 1), ('e', 1), ('l', 2), ('o', 1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "but it's probably best to formalize this in a unit test. I'm using pytest here, but you could use unittest or your favourite test runner, the principal is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def test_run_length_encode():\n",
    "    input_data = \"hello\"\n",
    "    expected = [('h', 1), ('e', 1), ('l', 2), ('o', 1)]\n",
    "    actual = encode(input_data)\n",
    "    assert actual == expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "!py.test -k test_run_length_encode -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def test_run_length_decode():\n",
    "    input_data = [('h', 1), ('e', 1), ('l', 2), ('o', 1)]\n",
    "    expected = \"hello\"\n",
    "    actual = decode(input_data)\n",
    "    assert actual == expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "!py.test -k test_run_length_decode -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import pytest\n",
    "\n",
    "examples = ['hello', 'python', 'uhm...']\n",
    "\n",
    "@pytest.mark.parametrize('input_data', examples)\n",
    "def test_parameterized_run_length_encode_decode(input_data):\n",
    "    assert decode(encode(input_data)) == input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "!py.test -k test_parameterized_run_length_encode_decode -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import random, string\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "random_letter = lambda: random.choice(string.ascii_letters)\n",
    "random_range = lambda m: range(random.randint(0, m))\n",
    "random_word = lambda m: (random_letter() for i in random_range(m))\n",
    "random_words = lambda n, m: (''.join(random_word(m)) for n in range(n))\n",
    "\n",
    "@pytest.mark.parametrize('input_data', random_words(5, 10))\n",
    "def test_fuzzed_run_length_encode_decode(input_data):\n",
    "    assert decode(encode(input_data)) == input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "!py.test -k test_fuzzed_run_length_encode_decode -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from hypothesis import strategies as st\n",
    "from hypothesis import given\n",
    "\n",
    "@given(st.text())\n",
    "def test_property_based_run_length_encode_decode(input_data):\n",
    "    assert decode(encode(input_data)) == input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "!py.test -k test_property_based_run_length_encode_decode -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def encode_fixed(input_string):\n",
    "    count = 1\n",
    "    prev = ''\n",
    "    lst = []\n",
    "    character = ''\n",
    "    for character in input_string:\n",
    "        if character != prev:\n",
    "            if prev:\n",
    "                lst.append((prev, count))\n",
    "            count = 1\n",
    "            prev = character\n",
    "        else:\n",
    "            count += 1\n",
    "    else:\n",
    "        lst.append((character, count))\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "@given(st.text())\n",
    "def test_property_based_run_length_encode_fixed_decode(input_data):\n",
    "    assert decode(encode_fixed(input_data)) == input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "!py.test -k test_property_based_run_length_encode_fixed_decode -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class Queue(object):\n",
    "\n",
    "    def __init__(self, max_size):\n",
    "        self._buffer = [None] * max_size\n",
    "        self._in, self._out, self.max_size = 0, 0, max_size\n",
    "\n",
    "    def put(self, item):\n",
    "        self._buffer[self._in] = item\n",
    "        self._in = (self._in + 1) % self.max_size\n",
    "\n",
    "    def get(self):\n",
    "        result = self._buffer[self._out]\n",
    "        self._out = (self._out + 1) % self.max_size\n",
    "        return result\n",
    "\n",
    "    def __len__(self):\n",
    "        return (self._in - self._out) % self.max_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from hypothesis import strategies as st\n",
    "from hypothesis.stateful import RuleBasedStateMachine, rule, precondition\n",
    "\n",
    "class QueueMachine(RuleBasedStateMachine):\n",
    "\n",
    "    SystemUnderTest, Model = Queue, list\n",
    "    system_under_test, model, max_size = None, None, 0\n",
    "\n",
    "    @precondition(lambda self: self.system_under_test is None)\n",
    "    @rule(max_size=st.integers(min_value=1, max_value=10))\n",
    "    def new(self, max_size):\n",
    "        self.system_under_test = self.SystemUnderTest(max_size)\n",
    "        self.model = self.Model()\n",
    "        self.max_size = max_size\n",
    "\n",
    "    @precondition(lambda self: self.system_under_test is not None)\n",
    "    @rule(item=st.integers())\n",
    "    def put(self, item):\n",
    "        self.system_under_test.put(item)\n",
    "        self.model.append(item)\n",
    "\n",
    "    @precondition(lambda self: self.system_under_test is not None\n",
    "                               and len(self.model))\n",
    "    @rule()\n",
    "    def get(self):\n",
    "        actual = self.system_under_test.get()\n",
    "        model = self.model.pop()\n",
    "        assert actual == model\n",
    "\n",
    "    @precondition(lambda self: self.system_under_test is not None)\n",
    "    @rule()\n",
    "    def size(self):\n",
    "        actual = len(self.system_under_test)\n",
    "        model = len(self.model)\n",
    "        assert actual == model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "test_model_based_1 = QueueMachine.TestCase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "!py.test -k test_model_based_1 -q --tb short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class QueueMachine2(QueueMachine):\n",
    "\n",
    "    @precondition(lambda self: self.system_under_test is not None)\n",
    "    @rule(item=st.integers())\n",
    "    def put(self, item):\n",
    "        self.system_under_test.put(item)\n",
    "        self.model.insert(0, item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "test_model_based_2 = QueueMachine2.TestCase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "!py.test -k test_model_based_2 -q --tb short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class QueueMachine3(QueueMachine2):\n",
    "\n",
    "    @precondition(lambda self: self.system_under_test is not None\n",
    "                               and len(self.model) < self.max_size)\n",
    "    @rule(item=st.integers())\n",
    "    def put(self, item):\n",
    "        super(QueueMachine3, self).put(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "test_model_based_3 = QueueMachine3.TestCase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "!py.test -k test_model_based_3 -q --tb short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class Queue2(Queue):\n",
    "    def __init__(self, max_size):\n",
    "        super(Queue2, self).__init__(max_size + 1)\n",
    "\n",
    "class QueueMachine4(QueueMachine3):\n",
    "    SystemUnderTest = Queue2\n",
    "\n",
    "test_model_based_4 = QueueMachine4.TestCase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "!py.test -k test_model_based_4 -q --tb short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "$('#clear_all_output').click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<link href=\"https://fonts.googleapis.com/css?family=Poppins\" rel=\"stylesheet\">\n",
    "<style>body { font-family: 'Poppins', serif !important; }</style>\n"
   ]
  }
 ],
 "metadata": {
  "livereveal": {
   "scroll": true,
   "theme": "black",
   "transition": "fade"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
