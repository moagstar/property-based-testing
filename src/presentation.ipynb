{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "$('#run_all_cells_below').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "from hypothesis import settings\n",
    "settings.register_profile(\"presentation\", settings(database_file=None, max_examples=100))\n",
    "settings.load_profile(\"presentation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Property Based Testing\n",
    "## (Using Hypothesis)<br><br><br>\n",
    "### Amsterdam Python Meetup\n",
    "### 26 April 2017<br><br><br>\n",
    "### Daniel Bradburn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Property based testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Choosing properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Generating data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Model based testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Django"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Property Based Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "say we have a run length encoding function. We encode a string as characters and the number of consecutive occurrences of that character. let's just test this out with something simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def encode(input_string):\n",
    "    count = 1\n",
    "    prev = ''\n",
    "    lst = []\n",
    "    for character in input_string:\n",
    "        if character != prev:\n",
    "            if prev:\n",
    "                lst.append((prev, count))\n",
    "            count = 1\n",
    "            prev = character\n",
    "        else:\n",
    "            count += 1\n",
    "    else:\n",
    "        lst.append((character, count))\n",
    "    return ''.join(x + str(n) for x, n in lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'h1e1l6o1'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode('hellllllo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "and we also have a decode function which reconstructs the string let's just check this function, let's use the output from the encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def decode(lst):\n",
    "    curr_digits, curr_letter, output = '', '', ''\n",
    "    for c in lst:\n",
    "        if c in map(str, range(10)):\n",
    "            curr_digits += c\n",
    "        else:\n",
    "            if curr_digits:\n",
    "                output += curr_letter * int(curr_digits)\n",
    "            curr_letter, curr_digits = c, ''\n",
    "    output += curr_letter * int(curr_digits)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hellllllo'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode('h1e1l6o1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "but it's probably best to formalize this in a unit test. I'm using pytest here, but you could use unittest or your favourite test runner, the principal is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def test_run_length_encode():\n",
    "    input_data = 'hello'\n",
    "    expected = 'h1e1l2o1'\n",
    "    actual = encode(input_data)\n",
    "    assert actual == expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\r\n",
      "\r\n",
      "======================== 34 tests deselected =========================\r\n",
      "\r\n",
      "1 passed, 34 deselected in 0.40 seconds\r\n"
     ]
    }
   ],
   "source": [
    "!sh pytest_run.sh test_run_length_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def test_run_length_decode():\n",
    "    input_data = 'h1e1l2o1'\n",
    "    expected = 'hello'\n",
    "    actual = decode(input_data)\n",
    "    assert actual == expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\r\n",
      "\r\n",
      "======================== 34 tests deselected =========================\r\n",
      "\r\n",
      "1 passed, 34 deselected in 0.39 seconds\r\n"
     ]
    }
   ],
   "source": [
    "!sh pytest_run.sh test_run_length_decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import pytest\n",
    "\n",
    "examples = ['hello', 'python', 'uhm...']\n",
    "\n",
    "@pytest.mark.parametrize('input_data', examples)\n",
    "def test_parameterized_run_length_encode_decode(input_data):\n",
    "    assert decode(encode(input_data)) == input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\r\n",
      "\r\n",
      "======================== 68 tests deselected =========================\r\n",
      "\r\n",
      "3 passed, 68 deselected in 0.39 seconds\r\n"
     ]
    }
   ],
   "source": [
    "!sh pytest_run.sh test_parameterized_run_length_encode_decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from random import seed, choice, randint\n",
    "from itertools import repeat\n",
    "\n",
    "seed(0)\n",
    "\n",
    "randletter = lambda _: chr(choice(range(1, 255)))\n",
    "randrange = lambda length: range(randint(0, length))\n",
    "randword = lambda length: ''.join(map(randletter, randrange(length)))\n",
    "randwords = lambda num, length: (randword(length) for _ in range(num))\n",
    "\n",
    "@pytest.mark.parametrize('input_data', randwords(num=10, length=10))\n",
    "def test_fuzzed_run_length_encode_decode(input_data):\n",
    "    assert decode(encode(input_data)) == input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........\r\n",
      "\r\n",
      "======================== 25 tests deselected =========================\r\n",
      "\r\n",
      "10 passed, 25 deselected in 0.42 seconds\r\n"
     ]
    }
   ],
   "source": [
    "!sh pytest_run.sh test_fuzzed_run_length_encode_decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from hypothesis import strategies as st, given, assume\n",
    "\n",
    "@given(st.text())\n",
    "def test_property_based_run_length_encode_decode(input_data):\n",
    "    assert decode(encode(input_data)) == input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F\r\n",
      "\r\n",
      "============================== FAILURES ==============================\r\n",
      "\r\n",
      "\r\n",
      "____________ test_property_based_run_length_encode_decode ____________\r\n",
      "\r\n",
      "\r\n",
      "test.py:76: in test_property_based_run_length_encode_decode\r\n",
      "    def test_property_based_run_length_encode_decode(input_data):\r\n",
      "\r\n",
      ".venv/hypothesis/core.py:524: in wrapped_test\r\n",
      "    print_example=True, is_final=True\r\n",
      "\r\n",
      ".venv/hypothesis/executors.py:58: in default_new_style_executor\r\n",
      "    return function(data)\r\n",
      "\r\n",
      ".venv/hypothesis/core.py:111: in run\r\n",
      "    return test(*args, **kwargs)\r\n",
      "\r\n",
      "test.py:77: in test_property_based_run_length_encode_decode\r\n",
      "    assert decode(encode(input_data)) == input_data\r\n",
      "\r\n",
      "test.py:19: in encode\r\n",
      "    lst.append((character, count))\r\n",
      "E   UnboundLocalError: local variable 'character' referenced before assignment\r\n",
      "\r\n",
      "----------------------------- Hypothesis -----------------------------\r\n",
      "\r\n",
      "Falsifying example: test_property_based_run_length_encode_decode(input_data='')\r\n",
      "\r\n",
      "======================== 70 tests deselected =========================\r\n",
      "\r\n",
      "1 failed, 70 deselected in 0.49 seconds\r\n"
     ]
    }
   ],
   "source": [
    "!sh pytest_run.sh test_property_based_run_length_encode_decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def encode_fixed(input_string):\n",
    "    count = 1\n",
    "    prev = ''\n",
    "    lst = []\n",
    "    character = ''\n",
    "    for character in input_string:\n",
    "        if character != prev:\n",
    "            if prev:\n",
    "                lst.append((prev, count))\n",
    "            count = 1\n",
    "            prev = character\n",
    "        else:\n",
    "            count += 1\n",
    "    else:\n",
    "        lst.append((character, count))\n",
    "    return ''.join(x + str(n) for x, n in lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "@given(st.text())\n",
    "def test_property_based_fixed_run_length_encode_decode(input_data):\n",
    "    assert decode(encode_fixed(input_data)) == input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F\r\n",
      "\r\n",
      "============================== FAILURES ==============================\r\n",
      "\r\n",
      "\r\n",
      "_________ test_property_based_fixed_run_length_encode_decode _________\r\n",
      "\r\n",
      "\r\n",
      "test.py:99: in test_property_based_fixed_run_length_encode_decode\r\n",
      "    def test_property_based_fixed_run_length_encode_decode(input_data):\r\n",
      "\r\n",
      ".venv/hypothesis/core.py:524: in wrapped_test\r\n",
      "    print_example=True, is_final=True\r\n",
      "\r\n",
      ".venv/hypothesis/executors.py:58: in default_new_style_executor\r\n",
      "    return function(data)\r\n",
      "\r\n",
      ".venv/hypothesis/core.py:111: in run\r\n",
      "    return test(*args, **kwargs)\r\n",
      "\r\n",
      "test.py:100: in test_property_based_fixed_run_length_encode_decode\r\n",
      "    assert decode(encode_fixed(input_data)) == input_data\r\n",
      "E   AssertionError\r\n",
      "\r\n",
      "----------------------------- Hypothesis -----------------------------\r\n",
      "\r\n",
      "Falsifying example: test_property_based_fixed_run_length_encode_decode(input_data='0')\r\n",
      "\r\n",
      "======================== 70 tests deselected =========================\r\n",
      "\r\n",
      "1 failed, 70 deselected in 0.51 seconds\r\n"
     ]
    }
   ],
   "source": [
    "!sh pytest_run.sh test_property_based_fixed_run_length_encode_decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from hypothesis import settings, Verbosity\n",
    "\n",
    "@settings(verbosity=Verbosity.verbose)\n",
    "@given(st.text())\n",
    "def test_property_based_show_fixed_run_length_encode_decode(input_data):\n",
    "    assert decode(encode_fixed(input_data)) == input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F\r\n",
      "\r\n",
      "============================== FAILURES ==============================\r\n",
      "\r\n",
      "\r\n",
      "______ test_property_based_show_fixed_run_length_encode_decode _______\r\n",
      "\r\n",
      "\r\n",
      "test.py:106: in test_property_based_show_fixed_run_length_encode_decode\r\n",
      "    @given(st.text())\r\n",
      "\r\n",
      ".venv/hypothesis/core.py:524: in wrapped_test\r\n",
      "    print_example=True, is_final=True\r\n",
      "\r\n",
      ".venv/hypothesis/executors.py:58: in default_new_style_executor\r\n",
      "    return function(data)\r\n",
      "\r\n",
      ".venv/hypothesis/core.py:111: in run\r\n",
      "    return test(*args, **kwargs)\r\n",
      "\r\n",
      "test.py:108: in test_property_based_show_fixed_run_length_encode_decode\r\n",
      "    assert decode(encode_fixed(input_data)) == input_data\r\n",
      "E   AssertionError\r\n",
      "\r\n",
      "----------------------------- Hypothesis -----------------------------\r\n",
      "\r\n",
      "Trying example: test_property_based_show_fixed_run_length_encode_decode(input_data='G\\nd\\x1cÍ≤ä')\r\n",
      "Trying example: test_property_based_show_fixed_run_length_encode_decode(input_data='O')\r\n",
      "Trying example: test_property_based_show_fixed_run_length_encode_decode(input_data='Or\\n')\r\n",
      "Trying example: test_property_based_show_fixed_run_length_encode_decode(input_data='\\n·Å≤ÂΩ©Á®§\\U0003bf92')\r\n",
      "Trying example: test_property_based_show_fixed_run_length_encode_decode(input_data='\\U0003bf92·Å≤\\ue769\\U00010224')\r\n",
      "Trying example: test_property_based_show_fixed_run_length_encode_decode(input_data='\\U00033f92·ë≤\\U0002e769\\U0003bf92\\U0008daf7\\U0007fd53@‚ßõ')\r\n",
      "Trying example: test_property_based_show_fixed_run_length_encode_decode(input_data='\\U000b3f92')\r\n",
      "Trying example: test_property_based_show_fixed_run_length_encode_decode(input_data='\\U000f3f92√á\\U00058a4a')\r\n",
      "Trying example: test_property_based_show_fixed_run_length_encode_decode(input_data='\\U000f3f52«á\\U00058e4a')\r\n",
      "Trying example: test_property_based_show_fixed_run_length_encode_decode(input_data='\\U000f3f52')\r\n",
      "Trying example: test_property_based_show_fixed_run_length_encode_decode(input_data='')\r\n",
      "Trying example: test_property_based_show_fixed_run_length_encode_decode(input_data='Èáñ·±Å√âßÖò@\\U000362f3\\x13$7')\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/home/moagstar/Projects/property-based-testi\r\n",
      ".venv/hypothesis/core.py\", line 446, in evaluate_test_data\r\n",
      "    search_strategy, test,\r\n",
      "  File \"/home/moagstar/Projects/property-based-testi\r\n",
      ".venv/hypothesis/executors.py\", line 58, in default_new_style_executor\r\n",
      "  File \"/home/moagstar/Projects/property-based-testi\r\n",
      ".venv/hypothesis/core.py\", line 111, in run\r\n",
      "  File \"test.py\", line 108, in test_property_based_show_fixed_run_length_encode_decode\r\n",
      "AssertionError\r\n",
      "\r\n",
      "Trying example: test_property_based_show_fixed_run_length_encode_decode(input_data='Èáñ·±Å√â\\U000362f3\\x13$7')\r\n",
      "Trying example: test_property_based_show_fixed_run_length_encode_decode(input_data='Èáñ·±Å√â\\U000362f3\\x13')\r\n",
      "Trying example: test_property_based_show_fixed_run_length_encode_decode(input_data='ê°åê†∞êÆä\\U00011927')\r\n",
      "Trying example: test_property_based_show_fixed_run_length_encode_decode(input_data='Èáñ√â\\U000362f3\\x13$7')\r\n",
      "Trying example: test_property_based_show_fixed_run_length_encode_decode(input_data='Èáñ√â\\U00011927')\r\n",
      "Trying example: test_property_based_show_fixed_run_length_encode_decode(input_data='Èáñ√â\\x13$7')\r\n",
      "Trying example: test_property_based_show_fixed_run_length_encode_decode(input_data='Èáñ√â\\x13')\r\n",
      "Trying example: test_property_based_show_fixed_run_length_encode_decode(input_data='\\x13$7')\r\n",
      "Trying example: test_property_based_show_fixed_run_length_encode_decode(input_data='\\x13$')\r\n",
      "Trying example: test_property_based_show_fixed_run_length_encode_decode(input_data='7')\r\n",
      "Trying example: test_property_based_show_fixed_run_length_encode_decode(input_data='1')\r\n",
      "Trying example: test_property_based_show_fixed_run_length_encode_decode(input_data='0')\r\n",
      "Falsifying example: test_property_based_show_fixed_run_length_encode_decode(input_data='0')\r\n",
      "\r\n",
      "======================== 70 tests deselected =========================\r\n",
      "\r\n",
      "1 failed, 70 deselected in 0.51 seconds\r\n"
     ]
    }
   ],
   "source": [
    "!sh pytest_run.sh test_property_based_show_fixed_run_length_encode_decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "@pytest.mark.parametrize('input_data', randwords(num=10, length=20))\n",
    "def test_fuzzed_more_run_length_encode_decode(input_data):\n",
    "    assert decode(encode_fixed(input_data)) == input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...F..FF..\r\n",
      "\r\n",
      "============================== FAILURES ==============================\r\n",
      "\r\n",
      "__ test_fuzzed_more_run_length_encode_decode[\\xb5\\xdf\\x111\\xeb\\x929>\\xce\\xf8] __\r\n",
      "\r\n",
      "test.py:114: in test_fuzzed_more_run_length_encode_decode\r\n",
      "    assert decode(encode_fixed(input_data)) == input_data\r\n",
      "E   AssertionError\r\n",
      " test_fuzzed_more_run_length_encode_decode[\\xef~\\x1cN\\x8eK\\xb5 \\x8dV\\xd1\\xed\\x8b5\\xf7\\xcd] \r\n",
      " test_fuzzed_more_run_length_encode_decode[\\x8d\\x97Jr\\x18\\x99\\xcdcR\\x94>K01\\xd30\\t\\x9d\\xfc] \r\n",
      "\r\n",
      "======================== 30 tests deselected =========================\r\n",
      "\r\n",
      "3 failed, 7 passed, 30 deselected in 0.45 seconds\r\n"
     ]
    }
   ],
   "source": [
    "!sh pytest_run.sh test_fuzzed_more_run_length_encode_decode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Summary (TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Property patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from hypothesis import given, strategies as st\n",
    "\n",
    "@given(st.lists(st.integers(), min_size=1))\n",
    "def test_round_and_around(c):\n",
    "    assert c[::-1][::-1] == c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\r\n",
      "\r\n",
      "======================== 30 tests deselected =========================\r\n",
      "\r\n",
      "1 passed, 30 deselected in 0.44 seconds\r\n"
     ]
    }
   ],
   "source": [
    "!sh pytest_run.sh test_round_and_around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "@given(st.integers(), st.integers())\n",
    "def test_different_paths_same_destination_add(x, y):\n",
    "    assert x + y == y + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\r\n",
      "\r\n",
      "======================== 30 tests deselected =========================\r\n",
      "\r\n",
      "1 passed, 30 deselected in 0.41 seconds\r\n"
     ]
    }
   ],
   "source": [
    "!sh pytest_run.sh test_different_paths_same_destination_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "@given(st.integers(), st.integers())\n",
    "def test_there_and_back_again_add(m, n):\n",
    "    assert m + n - n == m\n",
    "\n",
    "@given(st.text())\n",
    "def test_there_and_back_again_encode_decode(t):\n",
    "    assert t.encode('utf-8').decode('utf-8') == t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\r\n",
      "\r\n",
      "======================== 29 tests deselected =========================\r\n",
      "\r\n",
      "2 passed, 29 deselected in 0.48 seconds\r\n"
     ]
    }
   ],
   "source": [
    "!sh pytest_run.sh test_there_and_back_again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from heapq import heapify, heappop\n",
    "\n",
    "@given(st.lists(st.integers(), min_size=1))\n",
    "def test_some_things_never_change(c):\n",
    "    smallest = min(c)\n",
    "    heapify(c)\n",
    "    assert heappop(c) == smallest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\r\n",
      "\r\n",
      "======================== 30 tests deselected =========================\r\n",
      "\r\n",
      "1 passed, 30 deselected in 0.43 seconds\r\n"
     ]
    }
   ],
   "source": [
    "!sh pytest_run.sh test_some_things_never_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "@given(st.lists(st.integers()))\n",
    "def test_the_more_things_change_the_more_they_stay_the_same(c):\n",
    "    assert set(c) == set(set(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\r\n",
      "\r\n",
      "======================== 30 tests deselected =========================\r\n",
      "\r\n",
      "1 passed, 30 deselected in 0.43 seconds\r\n"
     ]
    }
   ],
   "source": [
    "!sh pytest_run.sh test_the_more_things_change_the_more_they_stay_the_same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def test_hard_to_prove_easy_to_verify():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\r\n",
      "\r\n",
      "======================== 30 tests deselected =========================\r\n",
      "\r\n",
      "1 passed, 30 deselected in 0.38 seconds\r\n"
     ]
    }
   ],
   "source": [
    "!sh pytest_run.sh test_hard_to_prove_easy_to_verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def test_two_heads_are_better_than_one():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\r\n",
      "\r\n",
      "======================== 30 tests deselected =========================\r\n",
      "\r\n",
      "1 passed, 30 deselected in 0.38 seconds\r\n"
     ]
    }
   ],
   "source": [
    "!sh pytest_run.sh test_two_heads_are_better_than_one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Summary (TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-113"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hypothesis import strategies as st\n",
    "\n",
    "st.integers().example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'√™\\U00014cde\\x0bËß°ÁÄæ\\x1ew√îÂ£û√Ç∆á‚ö¶„∫é\\U00060425'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.text().example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.floats().example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-10490,\n",
       " -73,\n",
       " 62652,\n",
       " -6695,\n",
       " 82,\n",
       " 177,\n",
       " -22358454268,\n",
       " -166,\n",
       " 24254,\n",
       " -243,\n",
       " 42165,\n",
       " 52024,\n",
       " 15,\n",
       " -45,\n",
       " 60716,\n",
       " -61,\n",
       " -109,\n",
       " 188,\n",
       " -73,\n",
       " 124,\n",
       " 39]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.lists(st.integers()).example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': [1.333431775331741e-273,\n",
       "  [],\n",
       "  -2.630755031582877e+18,\n",
       "  [None, None],\n",
       "  {'\\U0005accc\\x13\\U000ae5f7': ''},\n",
       "  {'≈ë\\U0005c4d1': True},\n",
       "  -7.494265036033925e+18,\n",
       "  ['H\\x18', None],\n",
       "  {'': '\\U00032ed08≈™Ïª£√ü≈å\\x11‰õµ„â™\\U0007ba8a√Ω\\x18\\nI',\n",
       "   '1Ê©º\\n\\U000a5bfb\\nñ§õ\\x08F': False,\n",
       "   'G\\x92\\U0010c2f4,': None,\n",
       "   '√¶*': -1.7976931348623157e+308,\n",
       "   '≈ã\\U00032791': '',\n",
       "   '‡≠†m\\n\\U000c9700\\n…ôÁªø': -inf,\n",
       "   '·™ê¬•Íã°WR\\x013≈è(ÊÇá\\x15Êùå\\xad≈û': True,\n",
       "   'Îõ°\\U0010565fw„±†': None,\n",
       "   '\\U0004228b': None,\n",
       "   '\\U00069ca7¬¶„≤†': None,\n",
       "   '\\U000df3cb{7': -3.3932096819187e+18,\n",
       "   '\\U000f494f\\nÂ¢©\\t\\x0bÔ∏º\\x13\\x17': '\\U000f263b\\U00064a00¬≥\\x12p√¶‚è™'},\n",
       "  nan,\n",
       "  {'': None,\n",
       "   '\\x14\\U000d71b3ÊÄÉ-û°èÍÄ≥': 8.612447227626119e+18,\n",
       "   '\\U000916b7': 'ƒÅ\\U0006abb4'}],\n",
       " 'ÂÅã#\\nÏµíIÁòÆ√ú\\U000c168e√º\\U000bc182\\U00042969\\n‰©Ø': '\\tÂäπ\\nË¨ï\\U00045649',\n",
       " \"Âßù%\\U0004f48cU'b√É{\": [None],\n",
       " 'Ï¶å\\x17¬©\\U0005ded0\\U001023d1': [None, False, False, True]}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes = st.floats() | st.booleans() | st.text() | st.none()\n",
    "children = lambda x: st.lists(x) | st.dictionaries(st.text(), x)\n",
    "st.recursive(nodes, children).example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "@st.composite\n",
    "def composite_strategy(draw):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Summary (TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model Based Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class Queue(object):\n",
    "\n",
    "    def __init__(self, max_size):\n",
    "        self._buffer = [None] * max_size\n",
    "        self._in, self._out, self.max_size = 0, 0, max_size\n",
    "\n",
    "    def put(self, item):\n",
    "        self._buffer[self._in] = item\n",
    "        self._in = (self._in + 1) % self.max_size\n",
    "\n",
    "    def get(self):\n",
    "        result = self._buffer[self._out]\n",
    "        self._out = (self._out + 1) % self.max_size\n",
    "        return result\n",
    "\n",
    "    def __len__(self):\n",
    "        return (self._in - self._out) % self.max_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('new', 'put', 'get', 'size'),\n",
       " ('new', 'put', 'size', 'get'),\n",
       " ('new', 'get', 'put', 'size'),\n",
       " ('new', 'get', 'size', 'put'),\n",
       " ('new', 'size', 'put', 'get'),\n",
       " ('new', 'size', 'get', 'put'),\n",
       " ('put', 'new', 'get', 'size'),\n",
       " ('put', 'new', 'size', 'get'),\n",
       " ('put', 'get', 'new', 'size'),\n",
       " ('put', 'get', 'size', 'new'),\n",
       " ('put', 'size', 'new', 'get'),\n",
       " ('put', 'size', 'get', 'new'),\n",
       " ('get', 'new', 'put', 'size'),\n",
       " ('get', 'new', 'size', 'put'),\n",
       " ('get', 'put', 'new', 'size'),\n",
       " ('get', 'put', 'size', 'new'),\n",
       " ('get', 'size', 'new', 'put'),\n",
       " ('get', 'size', 'put', 'new'),\n",
       " ('size', 'new', 'put', 'get'),\n",
       " ('size', 'new', 'get', 'put'),\n",
       " ('size', 'put', 'new', 'get'),\n",
       " ('size', 'put', 'get', 'new'),\n",
       " ('size', 'get', 'new', 'put'),\n",
       " ('size', 'get', 'put', 'new')]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "operations = 'new', 'put', 'get', 'size'\n",
    "list(itertools.permutations(operations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "What about performing the same operation 2 or 3 times in a row? Or passing different values\n",
    "to the various arguments these operations take? As we can see, in even\n",
    "the simplest of systems the number of test cases for a brute force method\n",
    "is unmanageable. There must be a better way.\n",
    "Of course not all permutations are valid, for example we don't want a test case of the\n",
    "form ``put``, ``get``, ``new``, ``size`` - it doesn't make sense to do perform any of\n",
    "the other operations on a queue until after it is created. What we need is a way to\n",
    "specify the valid operations for the system under test.\n",
    "In hypothesis we can derive a class from ``RuleBasedStateMachine`` where methods decorated\n",
    "with ``@rule`` are treated as states in the system. The ``@rule`` decorator is a bit like the\n",
    "``@given`` decorator, defining the strategies to use for generating argument values. However\n",
    "``@rule`` is only allowed in the context of a ``RuleBasedStateMachine``.\n",
    "All transitions between states are assumed valid, but the ``@precondition`` decorator can be\n",
    "used on a method to indicate whether a transition to this state is valid or not. In this\n",
    "way we can build a specification for the system under test.\n",
    "Using the ``Queue`` example, this is how the specification would look. To create\n",
    "a new queue we have the precondition that the queue must not already be\n",
    "created. For all other operations we check the precondition that the queue\n",
    "must have been created. And to get an item from the queue, we want to check\n",
    "that the queue is not empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from hypothesis import strategies as st\n",
    "from hypothesis.stateful import RuleBasedStateMachine, rule, precondition\n",
    "\n",
    "class QueueMachine(RuleBasedStateMachine):\n",
    "\n",
    "    Actual, Model = Queue, list\n",
    "\n",
    "    def is_created(self):\n",
    "        return hasattr(self, 'actual')\n",
    "\n",
    "    @precondition(lambda self: not self.is_created())\n",
    "    @rule(max_size=st.integers(min_value=1, max_value=10))\n",
    "    def new(self, max_size):\n",
    "        self.actual, self.model = self.Actual(max_size), self.Model()\n",
    "        self.max_size = max_size\n",
    "\n",
    "    @precondition(is_created)\n",
    "    @rule(item=st.integers())\n",
    "    def put(self, item):\n",
    "        self.actual.put(item)\n",
    "        self.model.append(item)\n",
    "\n",
    "    def is_not_empty(self):\n",
    "        return self.is_created() and len(self.model)\n",
    "\n",
    "    @precondition(is_not_empty)\n",
    "    @rule()\n",
    "    def get(self):\n",
    "        actual, model = self.actual.get(), self.model.pop()\n",
    "        assert actual == model\n",
    "\n",
    "    @precondition(is_created)\n",
    "    @rule()\n",
    "    def size(self):\n",
    "        actual, model = len(self.actual), len(self.model)\n",
    "        assert actual == model\n",
    "        \n",
    "test_model_based_1 = QueueMachine.TestCase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Besides specifying the various states and valid transitions, we want these\n",
    "methods to actually invoke the operation it represents on the system under\n",
    "test, but also we want to have a model which represents our system under\n",
    "test, and perform some similar operation on the model as well. We can then\n",
    "assert post conditions comparing the model and the system under test to\n",
    "determine if we got the expected behaviour or not. Of course you don't have\n",
    "to use a model, you can assert other properties about the system under test\n",
    "using this method.\n",
    "So in our queue example we can use a list as our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F\r\n",
      "\r\n",
      "============================== FAILURES ==============================\r\n",
      "\r\n",
      "\r\n",
      "_____________________ test_model_based_1.runTest _____________________\r\n",
      "\r\n",
      "\r\n",
      ".venv/hypothesis/stateful.py:182: in runTest\r\n",
      "    run_state_machine_as_test(state_machine_class)\r\n",
      "\r\n",
      ".venv/hypothesis/stateful.py:109: in run_state_machine_as_test\r\n",
      "    breaker.run(state_machine_factory(), print_steps=True)\r\n",
      "\r\n",
      ".venv/hypothesis/stateful.py:237: in run\r\n",
      "    state_machine.execute_step(value)\r\n",
      "\r\n",
      ".venv/hypothesis/stateful.py:512: in execute_step\r\n",
      "    result = rule.function(self, **data)\r\n",
      "\r\n",
      "test.py:220: in get\r\n",
      "    assert actual == model\r\n",
      "E   AssertionError\r\n",
      "\r\n",
      "----------------------------- Hypothesis -----------------------------\r\n",
      "\r\n",
      "Step #1: new(max_size=2)\r\n",
      "Step #2: put(item=0)\r\n",
      "Step #3: put(item=1)\r\n",
      "Step #4: get()\r\n",
      "\r\n",
      "======================== 32 tests deselected =========================\r\n",
      "\r\n",
      "1 failed, 32 deselected in 0.52 seconds\r\n"
     ]
    }
   ],
   "source": [
    "!sh pytest_run.sh test_model_based_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "RuleBasedStateMachine exposes a TestCase class which can be used like the\n",
    "standard TestCase classes.\n",
    "Let's run some tests.\n",
    "As you can see we got some failures, let's have a look at the error, it appears\n",
    "we created a new queue of size 2, we put a 0 into it, then put a 1 into it, and\n",
    "the performed a get. If we look at the assertion failure, we see that by the get\n",
    "our system under test gave us a 0, while the model gave us a 1. Now this is a\n",
    "FIFO queue, which is the behaviour we see from the actual system under test. We\n",
    "have here a bug in our model, our model is insufficient to represent the system\n",
    "under test. Luckily we can fix that by changing the append to a prepend in the\n",
    "put state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class QueueMachine2(QueueMachine):\n",
    "\n",
    "    @precondition(QueueMachine.is_created)\n",
    "    @rule(item=st.integers())\n",
    "    def put(self, item):\n",
    "        self.actual.put(item)\n",
    "        self.model.insert(0, item)\n",
    "        \n",
    "test_model_based_2 = QueueMachine2.TestCase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Let's run the tests again and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F\r\n",
      "\r\n",
      "============================== FAILURES ==============================\r\n",
      "\r\n",
      "\r\n",
      "_____________________ test_model_based_2.runTest _____________________\r\n",
      "\r\n",
      "\r\n",
      ".venv/hypothesis/stateful.py:182: in runTest\r\n",
      "    run_state_machine_as_test(state_machine_class)\r\n",
      "\r\n",
      ".venv/hypothesis/stateful.py:109: in run_state_machine_as_test\r\n",
      "    breaker.run(state_machine_factory(), print_steps=True)\r\n",
      "\r\n",
      ".venv/hypothesis/stateful.py:237: in run\r\n",
      "    state_machine.execute_step(value)\r\n",
      "\r\n",
      ".venv/hypothesis/stateful.py:512: in execute_step\r\n",
      "    result = rule.function(self, **data)\r\n",
      "\r\n",
      "test.py:226: in size\r\n",
      "    assert actual == model\r\n",
      "E   AssertionError\r\n",
      "\r\n",
      "----------------------------- Hypothesis -----------------------------\r\n",
      "\r\n",
      "Step #1: new(max_size=1)\r\n",
      "Step #2: put(item=0)\r\n",
      "Step #3: size()\r\n",
      "\r\n",
      "======================== 32 tests deselected =========================\r\n",
      "\r\n",
      "1 failed, 32 deselected in 0.52 seconds\r\n"
     ]
    }
   ],
   "source": [
    "!sh pytest_run.sh test_model_based_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "This time we encounter a different error. We create a new queue of size 1, we\n",
    "put a 0 into it, then put another 0 into it, and then ask for the size. Our\n",
    "actual system under test reports 0, while the model reports 2. Now the 0 is\n",
    "clearly wrong, but what is going on here? Well I create a queue of size 1\n",
    "and then I put 2 items into it. It's debatable about what the system should\n",
    "actually do here, maybe raise an exception, but for the sake of the tests\n",
    "we generated an invalid test case here, so this is a bug in our specification.\n",
    "We can fix this by altering the pre condition to ensure we don't try and put\n",
    "items on the queue if it is already full."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class QueueMachine3(QueueMachine2):\n",
    "\n",
    "    def is_not_full(self):\n",
    "        return self.is_created() and len(self.model) < self.max_size\n",
    "\n",
    "    @precondition(is_not_full)\n",
    "    @rule(item=st.integers())\n",
    "    def put(self, item):\n",
    "        self.actual.put(item)\n",
    "        self.model.insert(0, item)\n",
    "        \n",
    "test_model_based_3 = QueueMachine3.TestCase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Let's run the tests again with the updated model and specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\r\n",
      "======================== 33 tests deselected =========================\r\n",
      "\r\n",
      "33 deselected in 0.40 seconds\r\n"
     ]
    }
   ],
   "source": [
    "!sh pytest_run.sh test_model_based_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Now we get yet another error, this time with create a new queue of size 1, we put\n",
    "an item into it and we ask the size. Our model gives the correct answer, 1,\n",
    "but our actual system under test gives a size of 0, that's clearly wrong, I\n",
    "think this is a bug in the actual implementation of the system under test. Let's\n",
    "take a look at what is going here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class Queue2(Queue):\n",
    "    def __init__(self, max_size):\n",
    "        super(Queue2, self).__init__(max_size + 1)\n",
    "\n",
    "class QueueMachine4(QueueMachine3):\n",
    "    Actual = Queue2\n",
    "    \n",
    "test_model_based_4 = QueueMachine4.TestCase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\r\n",
      "\r\n",
      "======================== 34 tests deselected =========================\r\n",
      "\r\n",
      "1 passed, 34 deselected in 0.47 seconds\r\n"
     ]
    }
   ],
   "source": [
    "!sh pytest_run.sh test_model_based_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Tackles the problem of testing interactions between features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Complexity, is this a bug in the spec, model or system under test?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Django"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Real World Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "$('#clear_all_output').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<link href=\"https://fonts.googleapis.com/css?family=ABeeZee\" rel=\"stylesheet\">\n",
       "<style>body { font-family: 'ABeeZee', serif !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%HTML\n",
    "<link href=\"https://fonts.googleapis.com/css?family=ABeeZee\" rel=\"stylesheet\">\n",
    "<style>body { font-family: 'ABeeZee', serif !important; }</style>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "livereveal": {
   "scroll": true,
   "theme": "black",
   "transition": "fade"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}